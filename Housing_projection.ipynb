{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from torch.utils.data import TensorDataset\n",
    "from net import Net_1\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from utils import AverageMeter\n",
    "import math\n",
    "from Randomized import RandomizedLabelPrivacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset length:  16512 test_dataset length:  4128 device:  cuda\n"
     ]
    }
   ],
   "source": [
    "datasets = fetch_california_housing()\n",
    "X, y = datasets.data, datasets.target\n",
    "dataset_tensor = TensorDataset(\n",
    "            torch.Tensor(X), \n",
    "            torch.Tensor(y).flatten()\n",
    "            )\n",
    "train_length = int(len(dataset_tensor) * 0.8)\n",
    "test_length = len(dataset_tensor) - train_length\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "            dataset_tensor, (train_length, test_length), generator=torch.Generator().manual_seed(4))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('train_dataset length: ', len(train_dataset), 'test_dataset length: ', len(test_dataset), 'device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_optimal_interval2(interval_freq, node, epsilon, delta):\n",
    "    \n",
    "    # Step 3: RPWithPrior i.e. Algorithm 1 in paper\n",
    "    k = len(interval_freq)\n",
    "    fmax = 0 # max value of f\n",
    "    for i in range(k):\n",
    "        for j in range(i+1, k):\n",
    "            h = interval_freq[i] * node[i+1] + \\\n",
    "                torch.sum(interval_freq[i+1:j] * (node[i+2:j+1] - node[i+1:j])) - \\\n",
    "                    interval_freq[j] * node[j]\n",
    "            c1 = 2 * delta * interval_freq[i] - math.exp(-epsilon) *  h\n",
    "            slope = math.exp(-epsilon) * (interval_freq[j] - interval_freq[i])\n",
    "            \n",
    "            d11 = slope * node[j] -c1\n",
    "            d12 = slope * node[j+1] - c1\n",
    "            \n",
    "            c2 = 2 * delta * interval_freq[j] - math.exp(-epsilon) * h\n",
    "            \n",
    "            d21 = -slope * node[i] + c2\n",
    "            d22 = -slope * node[i+1] + c2\n",
    "            e1 = c1 / slope\n",
    "            e2 = c2 / slope\n",
    "            \n",
    "            A1max = node[i]\n",
    "            A2max = node[j]\n",
    "            h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                2 * delta+math.exp(-epsilon)*(A2max - A1max) )\n",
    "            if fmax < h1:\n",
    "                fmax = h1\n",
    "                A1 = A1max\n",
    "                A2 = A2max\n",
    "            \n",
    "            # (n_i,n_{j+1})\n",
    "            A2max = node[j+1]\n",
    "            h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                2 * delta+math.exp(-epsilon)*(A2max - A1max) )\n",
    "            if fmax < h1:\n",
    "                fmax = h1\n",
    "                A1 = A1max\n",
    "                A2 = A2max\n",
    "                \n",
    "            # (n_{i+1},n_{j+1})\n",
    "            A1max = node[i+1]\n",
    "            h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                2 * delta+math.exp(-epsilon)*(A2max - A1max) )\n",
    "            if fmax < h1:\n",
    "                fmax = h1\n",
    "                A1 = A1max\n",
    "                A2 = A2max \n",
    "                \n",
    "            # (n_{i+1},n_j)\n",
    "            A2max = node[j]\n",
    "            h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                2 * delta+math.exp(-epsilon)*(A2max - A1max) )\n",
    "            if fmax < h1:\n",
    "                fmax = h1\n",
    "                A1 = A1max\n",
    "                A2 = A2max\n",
    "                \n",
    "                \n",
    "            if d21 * d22 < 0:\n",
    "                # (e_2,n_j)\n",
    "                A1max = e2\n",
    "                A2max = node[j]\n",
    "                \n",
    "                h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                    2 * delta+math.exp(-epsilon)*(A2max - A1max) )\n",
    "                if fmax < h1:\n",
    "                    fmax = h1\n",
    "                    A1 = A1max\n",
    "                    A2 = A2max\n",
    "                \n",
    "                # (e_2,n_{j+1})\n",
    "                A2max = node[j+1]\n",
    "                \n",
    "                h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                    2 * delta+math.exp(-epsilon)*(A2max - A1max) )\n",
    "                if fmax < h1:\n",
    "                    fmax = h1\n",
    "                    A1 = A1max\n",
    "                    A2 = A2max\n",
    "            if d11 * d12 < 0:\n",
    "                # (n_i,e_1)\n",
    "                A1max = node[i]\n",
    "                A2max = e1\n",
    "                \n",
    "                h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                    2 * delta+math.exp(-epsilon)*(A2max - A1max) )\n",
    "                if fmax < h1:\n",
    "                    fmax = h1\n",
    "                    A1 = A1max\n",
    "                    A2 = A2max\n",
    "                \n",
    "                # (n_{i+1}, e_1)   \n",
    "                A1max = node[i+1]\n",
    "                \n",
    "                h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                    2 * delta+math.exp(-epsilon)*(A2max - A1max ) )\n",
    "                if fmax < h1:\n",
    "                    fmax = h1\n",
    "                    A1 = A1max\n",
    "                    A2 = A2max  \n",
    "                    \n",
    "            if  d11 * d12 < 0 and d21 * d22 < 0:  \n",
    "                # (e_2,e_1)\n",
    "                A1max = e2\n",
    "                A2max = e1      \n",
    "                h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                    2 * delta+math.exp(-epsilon)*(A2max - A1max ))\n",
    "                if fmax < h1:\n",
    "                    # fmax = h1\n",
    "                    A1 = A1max\n",
    "                    A2 = A2max\n",
    "    return A1, A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RPWithPrior3(train_loader, device, epsilon_total=0.1, delta=0.1):\n",
    "    mechanism = \"Laplace\"\n",
    "    # mechanism = \"Gaussian\"\n",
    "    # mechanism = \"staircase\"\n",
    "    epsilon1 = 0.017\n",
    "    epsilon = epsilon_total - epsilon1\n",
    "\n",
    "    rlp = RandomizedLabelPrivacy(epsilon1, mechanism, sensitivity=4.85, device=device)\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        target = y + rlp.noise(y.shape) #.cpu()\n",
    "\n",
    "        if i == 0:\n",
    "            x_sets = x\n",
    "            y_sets = y\n",
    "            target_sets = target \n",
    "        else:\n",
    "            x_sets = torch.cat((x_sets, x), 0)\n",
    "            y_sets = torch.cat((y_sets, y), 0)\n",
    "            target_sets = torch.cat((y_sets, target), 0)\n",
    "            \n",
    "        \n",
    "    target_sets = torch.max(target_sets, torch.zeros(target_sets.shape).to(device))\n",
    "    print(\"value\", torch.max(y_sets) - torch.min(y_sets))\n",
    "\n",
    "    # calculate the statistics of prior\n",
    "    target_mean = target_sets.mean()\n",
    "    target_std = target_sets.std() \n",
    "    \n",
    "    # Step 2: calculate the histogram of prior \n",
    "    # calculate the value in each interval of the histogram\n",
    "    k0 = ((torch.min(target_sets) - target_mean) / target_std ).floor().int().item()\n",
    "    k1 = ((torch.max(target_sets) - target_mean) / target_std ).ceil().int().item()\n",
    "    k = k1 - k0\n",
    "\n",
    "    node = torch.zeros(k+1) # node in paper x_0...x_k\n",
    "    interval_freq = torch.zeros(k) # value in each interval for histogram\n",
    "\n",
    "    # calculate the relative frequency(probability) of each interval\n",
    "    for i in range(k0, k1):\n",
    "        if i == k0:\n",
    "            node[i-k0] = torch.min(target_sets)\n",
    "        else: \n",
    "            node[i-k0] = target_mean + i * target_std\n",
    "        if i < k1 - 1:\n",
    "            in_range = (target_sets - target_mean >= i * target_std) & \\\n",
    "                    (target_sets - target_mean < (i + 1) * target_std)\n",
    "        else:\n",
    "            in_range = (target_sets - target_mean >= i * target_std) & \\\n",
    "                    (target_sets - target_mean <= (i + 1) * target_std)\n",
    "        interval_freq[i-k0] = in_range.sum().item()\n",
    "    node[k] = torch.max(target_sets) \n",
    "    interval_freq = interval_freq / len(target_sets)\n",
    "    \n",
    "    # Step 3: RPWithPrior i.e. Algorithm 1 in this paper\n",
    "    A1, A2 = compute_optimal_interval2(interval_freq, node, epsilon1, delta)\n",
    "    while (A2 - A1 < 2 * delta):\n",
    "        print('test')\n",
    "        delta = (A2 - A1) / 2\n",
    "        A1, A2 = compute_optimal_interval2(interval_freq, node, epsilon1, delta)\n",
    "    print(torch.min(y_sets),interval_freq, A1, A2, torch.max(y_sets),(y_sets<A1).sum()/len(y_sets), (y_sets>A2).sum()/len(y_sets))\n",
    "\n",
    "    print(\"delta\", delta)\n",
    "    \n",
    "    # Step 4: add noise to target  ##### Algorithm 2 in this paper \n",
    "    # projection by Equation (3.6)  \n",
    "    y_sets1 = y_sets.clone()   \n",
    "    y_sets1[y_sets1 < A1] = A1 \n",
    "    y_sets1[y_sets1 > A2] = A2\n",
    "\n",
    "    rate = 1 / (math.exp(epsilon) *2 * delta + (A2 -A1))\n",
    "    \n",
    "    prob1 = (y_sets1 - A1) * rate \n",
    "    prob1[prob1 < 0] = 0\n",
    "    prob2 = (A2 - y_sets1) * rate \n",
    "    prob2[prob2 < 0] = 0\n",
    "    prob2 = 1- prob2\n",
    "    \n",
    "    new_label = 2 * torch.ones(len(y_sets1), dtype= int).to(device)\n",
    "    random_tensor = torch.rand(len(y_sets1)).to(device)\n",
    "    new_label[random_tensor - prob1 < 0] = 1\n",
    "    new_label[random_tensor - prob2 > 0] = 3\n",
    "    #############################\n",
    "    y_tilde = y_sets1.clone()\n",
    "    \n",
    "    index = new_label == 1\n",
    "    y_tilde[index] = A1 - delta + torch.rand(index.sum()).to(device) * torch.max(\n",
    "        y_sets1[index] - A1,torch.zeros(index.sum()).to(device))\n",
    "    index = new_label == 2\n",
    "    y_tilde[index] = y_sets1[index] + delta * torch.empty_like(y_sets1[index]).uniform_(-1, 1).to(device)\n",
    "    index = new_label == 3\n",
    "    y_tilde[index] = A2 + delta - torch.rand(index.sum()).to(device) * torch.max(\n",
    "        A2 - y_sets1[index],torch.zeros(index.sum()).to(device))\n",
    "    \n",
    "    return x_sets, y_sets, y_tilde, delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value tensor(4.8500, device='cuda:0')\n",
      "tensor(0.1500, device='cuda:0') tensor([8.6581e-01, 1.3113e-01, 1.8029e-04, 2.4038e-04, 6.0096e-05, 3.6058e-04,\n",
      "        3.6058e-04, 0.0000e+00, 1.8029e-04, 1.2019e-04, 6.0096e-05, 2.4038e-04,\n",
      "        6.0096e-05, 1.2019e-04, 6.0096e-05, 6.0096e-05, 1.2019e-04, 1.2019e-04,\n",
      "        0.0000e+00, 6.0096e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.8029e-04, 1.2019e-04, 0.0000e+00, 0.0000e+00, 1.2019e-04, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0096e-05, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 6.0096e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 6.0096e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        6.0096e-05]) tensor(0.) tensor(3.4559) tensor(5.0000, device='cuda:0') tensor(0., device='cuda:0') tensor(0.1317, device='cuda:0')\n",
      "delta 0.7\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011044502258300781,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 50,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35f2244e06649dd9d74999b240cc897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40| Train Loss: 1.98| Train Loss: 1.40| Test Loss: 1.45 \n",
      "Epoch: 41| Train Loss: 1.99| Train Loss: 1.39| Test Loss: 1.45 \n",
      "Epoch: 42| Train Loss: 2.00| Train Loss: 1.55| Test Loss: 1.61 \n",
      "Epoch: 43| Train Loss: 2.00| Train Loss: 1.35| Test Loss: 1.41 \n",
      "Epoch: 44| Train Loss: 2.00| Train Loss: 1.62| Test Loss: 1.68 \n",
      "Epoch: 45| Train Loss: 2.01| Train Loss: 1.58| Test Loss: 1.63 \n",
      "Epoch: 46| Train Loss: 2.00| Train Loss: 1.50| Test Loss: 1.56 \n",
      "Epoch: 47| Train Loss: 1.99| Train Loss: 1.38| Test Loss: 1.44 \n",
      "Epoch: 48| Train Loss: 1.99| Train Loss: 1.44| Test Loss: 1.50 \n",
      "Epoch: 49| Train Loss: 1.99| Train Loss: 1.53| Test Loss: 1.58 \n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.05\n",
    "delta = 0.7\n",
    "model = Net_1(input = X.shape[1]).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()\n",
    "epoch = 50\n",
    "batch_size = 256\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "      shuffle=True, num_workers=8, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, \n",
    "      shuffle=True, num_workers=6, pin_memory=True)\n",
    "\n",
    "# Train                                      \n",
    "x_sets, y_sets, y_tilde, delta = RPWithPrior3(train_loader, device, epsilon_total= epsilon, delta=delta) \n",
    "\n",
    "# Train the model with the Label-DP dataset\n",
    "labeldp_dataset = torch.utils.data.TensorDataset(x_sets.detach().cpu(), y_tilde.detach().cpu())\n",
    "labeldp_loader = torch.utils.data.DataLoader(labeldp_dataset,\n",
    "            batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
    "for i in tqdm(range(epoch)):\n",
    "    losses = AverageMeter()\n",
    "    for j, (x, y) in enumerate(labeldp_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = loss_func(output.view(-1), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.update(loss.item(), x.shape[0])\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    if i >=40: #i % 5 == 0 or i == epoch-1:\n",
    "        train_loss = AverageMeter()\n",
    "        test_loss = AverageMeter()\n",
    "        with torch.no_grad():\n",
    "            for x, y in train_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = loss_func(output.view(-1), y)\n",
    "                train_loss.update(loss.item(), x.shape[0])\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = loss_func(output.view(-1), y)\n",
    "                test_loss.update(loss.item(), x.shape[0])\n",
    "        print(\"Epoch: {:>2}| Train Loss: {:.2f}| Train Loss: {:.2f}| Test Loss: {:.2f} \".format(i, \n",
    "                    losses.avg, train_loss.avg, test_loss.avg))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
